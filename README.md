# ğŸš€ Guest Post Index Checker

CÃ´ng cá»¥ kiá»ƒm tra index status cá»§a URLs trÃªn Google. Há»— trá»£ nháº­p domain Ä‘á»ƒ tá»± Ä‘á»™ng crawl sitemap vÃ  kiá»ƒm tra hÃ ng trÄƒm URLs cÃ¹ng lÃºc.

## âœ¨ TÃ­nh NÄƒng

### ğŸ“Š Backend (Flask + Python)
- âœ… **Kiá»ƒm tra index status** qua Serper.dev API
- âœ… **Auto-crawl sitemap**: Nháº­p domain â†’ tá»± Ä‘á»™ng láº¥y táº¥t cáº£ URLs tá»« sitemap.xml
- âœ… **Batch processing**: Xá»­ lÃ½ 10 URLs song song má»—i batch
- âœ… **Database SQLite**: LÆ°u lá»‹ch sá»­ theo domain sessions
- âœ… **Export CSV**: 3 loáº¡i - All URLs, Indexed, Not Indexed
- âœ… **API endpoints**:
  - `POST /api/check-index` - Kiá»ƒm tra URLs
  - `GET /api/domain-checks` - Lá»‹ch sá»­ domain checks
  - `GET /api/domain-checks/:id` - Chi tiáº¿t 1 domain check
  - `GET /api/export/:id?filter=all|indexed|not_indexed` - Export CSV
  - `GET /api/history` - Lá»‹ch sá»­ cÅ© (backward compatible)

### ğŸ¨ Frontend (React + Vite + Tailwind CSS)
- âœ… **UI hiá»‡n Ä‘áº¡i** vá»›i Tailwind CSS
- âœ… **Domain History**: Xem lá»‹ch sá»­ theo domain, má»Ÿ rá»™ng Ä‘á»ƒ xem chi tiáº¿t
- âœ… **Export buttons**: 3 nÃºt export riÃªng cho Indexed/Not Indexed/All
- âœ… **Real-time progress**: Hiá»ƒn thá»‹ progress bar khi checking
- âœ… **Stats cards**: Thá»‘ng kÃª tá»©c thá»i
- âœ… **Responsive**: Hoáº¡t Ä‘á»™ng tá»‘t trÃªn mobile

## ğŸ—ï¸ Cáº¥u TrÃºc Dá»± Ãn

```
guest_post_tool/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                      # Flask app entry
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env                        # Serper API key
â”‚   â”œâ”€â”€ check_history.db           # SQLite database
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ database.py            # Database operations
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ check_index.py         # Main API routes
â”‚   â”‚   â””â”€â”€ history.py             # History routes
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ serper_service.py      # Serper API integration
â”‚   â”‚   â””â”€â”€ sitemap_parser.py      # Sitemap crawler
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py              # Custom logger
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.js
    â”œâ”€â”€ tailwind.config.js
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx                 # Main component
        â”œâ”€â”€ services/
        â”‚   â””â”€â”€ api.js             # API client
        â””â”€â”€ components/
            â”œâ”€â”€ IndexCheckForm.jsx
            â”œâ”€â”€ ResultTable.jsx
            â””â”€â”€ DomainHistory.jsx   # Domain history vá»›i export

```

## ğŸ“¦ Database Schema

### `domain_checks`
LÆ°u metadata cá»§a má»—i láº§n check domain:
```sql
CREATE TABLE domain_checks (
    id INTEGER PRIMARY KEY,
    domain TEXT,
    total_urls INTEGER,
    indexed_count INTEGER,
    not_indexed_count INTEGER,
    error_count INTEGER,
    created_at TEXT
)
```

### `domain_check_urls`
LÆ°u chi tiáº¿t tá»«ng URL:
```sql
CREATE TABLE domain_check_urls (
    id INTEGER PRIMARY KEY,
    domain_check_id INTEGER,
    url TEXT,
    status TEXT,
    checked_at TEXT,
    FOREIGN KEY (domain_check_id) REFERENCES domain_checks(id)
)
```

## ğŸš€ CÃ i Äáº·t & Cháº¡y

### Backend

```bash
cd backend

# Táº¡o virtual environment
python3 -m venv venv
source venv/bin/activate  # Mac/Linux
# hoáº·c: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Táº¡o file .env vá»›i Serper API key
echo "SERPER_API_KEY=your_api_key_here" > .env

# Cháº¡y server
python app.py
# â†’ Server cháº¡y á»Ÿ http://127.0.0.1:5050
```

### Frontend

```bash
cd frontend

# Install dependencies
npm install

# Cháº¡y dev server
npm run dev
# â†’ Frontend cháº¡y á»Ÿ http://localhost:5173

# Build production
npm run build
```

## ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### 1. Kiá»ƒm Tra URLs

**CÃ¡ch 1: Nháº­p domain Ä‘Æ¡n giáº£n**
```
example.com
```
â†’ Tá»± Ä‘á»™ng crawl sitemap vÃ  kiá»ƒm tra táº¥t cáº£ URLs

**CÃ¡ch 2: Nháº­p URLs trá»±c tiáº¿p**
```
https://example.com/page-1/
https://example.com/page-2/
```

**CÃ¡ch 3: Mix cáº£ domain vÃ  URLs**
```
example.com
https://another-site.com/specific-page/
```

### 2. Export Dá»¯ Liá»‡u

Sau khi check xong, trong **Domain History**:
- Nháº¥n **Indexed** â†’ Export chá»‰ URLs Ä‘Ã£ index
- Nháº¥n **Not Indexed** â†’ Export chá»‰ URLs chÆ°a index
- Nháº¥n **All** â†’ Export táº¥t cáº£ URLs

File CSV format:
```csv
URL,Status,Checked At
https://example.com,Indexed âœ…,2025-10-24T14:07:05.059191+00:00
```

### 3. Xem Lá»‹ch Sá»­

Click vÃ o domain trong **Domain History** Ä‘á»ƒ:
- Xem chi tiáº¿t táº¥t cáº£ URLs Ä‘Ã£ check
- Export tá»«ng loáº¡i
- Xem thá»‘ng kÃª: Indexed/Not Indexed/Error count

## âš¡ Performance & Scalability

### Kháº£ NÄƒng Xá»­ LÃ½ HÃ ng TrÄƒm Domains

**âœ… CÃ“ THá»‚**, nhÆ°ng cáº§n lÆ°u Ã½:

#### Test Case: 100 domains Ã— 50 URLs = 5,000 URLs

| Metric | Value |
|--------|-------|
| Batch size | 10 URLs/batch |
| Time per batch | ~2-3 seconds |
| Total batches | 500 |
| **Estimated time** | **~20-25 phÃºt** |

#### Bottlenecks

1. **Serper API Rate Limit** âš ï¸
   - Free tier: 2,500 searches/month
   - Paid tier: Unlimited
   - â†’ Cáº§n **paid plan** cho hÃ ng nghÃ¬n URLs/thÃ¡ng

2. **Network latency**
   - Má»—i request máº¥t 1-3s
   - â†’ ÄÃ£ optimize báº±ng async + batch processing

3. **Database writes**
   - SQLite handle tá»‘t cho < 100k records
   - â†’ OK cho use case nÃ y

#### Recommendations

- **< 10 domains**: Cháº¡y ngay, khÃ´ng váº¥n Ä‘á»
- **10-50 domains**: Chá» 5-15 phÃºt
- **50-100 domains**: Chá» 15-30 phÃºt, cáº§n paid Serper API
- **> 100 domains**: NÃªn cháº¡y qua batch jobs, khÃ´ng nÃªn cháº¡y interactive

## ğŸ”§ API Documentation

### POST `/api/check-index`

Kiá»ƒm tra index status cho list URLs hoáº·c domains.

**Request:**
```json
{
  "urls": ["example.com", "https://another.com/page/"]
}
```

**Response:**
```json
{
  "domain_groups": {
    "example.com": [
      {
        "url": "https://example.com",
        "status": "Indexed âœ…",
        "checked_at": "2025-10-24T14:07:05.059191+00:00"
      }
    ]
  },
  "domain_check_ids": {
    "example.com": 1
  }
}
```

### GET `/api/domain-checks`

Láº¥y danh sÃ¡ch domain checks gáº§n nháº¥t.

**Query params:**
- `limit`: Sá»‘ lÆ°á»£ng records (default: 20)

**Response:**
```json
{
  "domain_checks": [
    {
      "id": 1,
      "domain": "example.com",
      "total_urls": 50,
      "indexed_count": 35,
      "not_indexed_count": 15,
      "error_count": 0,
      "created_at": "2025-10-24T14:07:05.068879+00:00"
    }
  ]
}
```

### GET `/api/domain-checks/:id`

Láº¥y chi tiáº¿t 1 domain check.

**Response:**
```json
{
  "domain": "example.com",
  "created_at": "2025-10-24T14:07:05.068879+00:00",
  "urls": [
    {
      "url": "https://example.com/page-1/",
      "status": "Indexed âœ…",
      "checked_at": "2025-10-24T14:07:05.059191+00:00"
    }
  ]
}
```

### GET `/api/export/:id`

Export domain check sang CSV.

**Query params:**
- `filter`: `all` (default), `indexed`, `not_indexed`

**Response:**
- File CSV download vá»›i tÃªn: `{domain}_{filter}_{timestamp}.csv`

## ğŸ› Troubleshooting

### Backend khÃ´ng cháº¡y

```bash
# Kiá»ƒm tra port 5050 cÃ³ bá»‹ chiáº¿m khÃ´ng
lsof -i :5050

# Kiá»ƒm tra .env cÃ³ SERPER_API_KEY chÆ°a
cat backend/.env

# Xem logs
cd backend
python app.py
```

### Frontend khÃ´ng connect Ä‘Æ°á»£c backend

1. Kiá»ƒm tra backend Ä‘ang cháº¡y á»Ÿ port 5050
2. Kiá»ƒm tra CORS Ä‘Ã£ báº­t trong `app.py`
3. Thá»­ curl Ä‘á»ƒ test:
```bash
curl http://127.0.0.1:5050/
```

### Serper API lá»—i

- Kiá»ƒm tra API key cÃ²n credit khÃ´ng: https://serper.dev/dashboard
- Free tier chá»‰ cÃ³ 2,500 searches/month
- Rate limit: ~1 request/second

### Database locked error

SQLite cÃ³ thá»ƒ bá»‹ lock náº¿u nhiá»u requests cÃ¹ng lÃºc:
```bash
# Reset database
rm backend/check_history.db
# Restart backend â†’ tá»± táº¡o DB má»›i
```

## ğŸ” Security Notes

- âš ï¸ **KhÃ´ng commit `.env`** file lÃªn git
- âš ï¸ API key Serper.dev pháº£i giá»¯ bÃ­ máº­t
- âœ… CORS Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh an toÃ n
- âœ… SQLite khÃ´ng expose ra internet (local only)

## ğŸ“ Requirements

### Backend
- Python 3.8+
- Flask 2.x
- aiohttp (async HTTP)
- BeautifulSoup4 (parse sitemap XML)
- Serper.dev API key

### Frontend
- Node.js 16+
- React 18
- Vite 5
- Tailwind CSS 4
- Lucide React (icons)

## ğŸ¯ Future Improvements

- [ ] Add Redis cache Ä‘á»ƒ giáº£m API calls
- [ ] Implement job queue (Celery) cho large batches
- [ ] Add authentication/multi-user support
- [ ] Schedule auto-recheck cho domains
- [ ] Export Excel (.xlsx) thay vÃ¬ CSV
- [ ] Add charts/visualizations cho stats
- [ ] Webhook notifications khi check xong

## ğŸ“„ License

MIT License - Feel free to use for personal/commercial projects

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first.

---

**Made with â¤ï¸ by Peter**
